{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a94724b",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5b5c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Reading JSON file with lines=True\n",
    "df = pd.read_csv(\"Sarcasm.csv\")\n",
    "# Display the dataframe\n",
    "df = df[['tweet','sarcastic']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86565a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6fb775",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26421cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from contractions import fix  # To handle contractions like don't -> do not\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text_advanced(text):\n",
    "    # Expand contractions\n",
    "    text = fix(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    # Remove excessive whitespaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "df['tweet'] = df['tweet'].astype(str).apply(clean_text_advanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd11d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing got college caffeine addiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love professor draw big question mark next ans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember hundred email company covid started g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today poppop told ‚Äú forced ‚Äù go college üôÉ okay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol littlewhitty mysticalmanatee also...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>population spike chicago 9 month ridiculous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>would think second last english class year pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>finally surfacing holiday scotland difficult d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>could prouder today well done every student go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>overheard 13 year old game friend smell like t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0                  thing got college caffeine addiction          1\n",
       "1     love professor draw big question mark next ans...          1\n",
       "2     remember hundred email company covid started g...          1\n",
       "3     today poppop told ‚Äú forced ‚Äù go college üôÉ okay...          1\n",
       "4     volphancarol littlewhitty mysticalmanatee also...          1\n",
       "...                                                 ...        ...\n",
       "3463        population spike chicago 9 month ridiculous          0\n",
       "3464  would think second last english class year pro...          0\n",
       "3465  finally surfacing holiday scotland difficult d...          0\n",
       "3466  could prouder today well done every student go...          0\n",
       "3467  overheard 13 year old game friend smell like t...          0\n",
       "\n",
       "[3467 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87365549",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56be476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarcastic\n",
       "0    2600\n",
       "1     867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271cd387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Class Distribution:\n",
      " sarcastic\n",
      "1    2600\n",
      "0    2600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Splitting the data into features and labels\n",
    "X = df['tweet'].values.reshape(-1, 1)  # Reshaping for the oversampler\n",
    "y = df['sarcastic']\n",
    "\n",
    "# Applying Random Oversampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = oversampler.fit_resample(X, y)\n",
    "\n",
    "# Creating a balanced DataFrame\n",
    "df = pd.DataFrame({'tweet': X_balanced.flatten(), 'sarcastic': y_balanced})\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"\\nBalanced Class Distribution:\\n\", df['sarcastic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032aa8f3",
   "metadata": {},
   "source": [
    "# Vectorization and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c0d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer() \n",
    "X = tfidf.fit_transform(df['tweet'])\n",
    "\n",
    "#  Define target variable\n",
    "y = df['sarcastic']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff2ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # `with_mean=False` due to sparse matrix\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c300d71",
   "metadata": {},
   "source": [
    "# Model Building and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3366a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.56%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       493\n",
      "           1       0.87      0.91      0.89       547\n",
      "\n",
      "    accuracy                           0.89      1040\n",
      "   macro avg       0.89      0.88      0.88      1040\n",
      "weighted avg       0.89      0.89      0.89      1040\n",
      "\n",
      "Confusion Matrix:\n",
      " [[421  72]\n",
      " [ 47 500]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Train SVM Model\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model = SVC(kernel='linear')  # Linear kernel is common for text classification\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e8e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 90.58%\n",
      "Classification Report (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       493\n",
      "           1       0.93      0.89      0.91       547\n",
      "\n",
      "    accuracy                           0.91      1040\n",
      "   macro avg       0.91      0.91      0.91      1040\n",
      "weighted avg       0.91      0.91      0.91      1040\n",
      "\n",
      "Confusion Matrix (Random Forest):\n",
      " [[454  39]\n",
      " [ 59 488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(\"Classification Report (Random Forest):\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix (Random Forest):\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5da163",
   "metadata": {},
   "source": [
    "# Sarcasm Detection System Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04ba90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sarcasm(new_headline):\n",
    "    cleaned_headline = clean_text_advanced(new_headline)  \n",
    "    transformed_headline = tfidf.transform([cleaned_headline])\n",
    "    prediction = model.predict(transformed_headline)\n",
    "    \n",
    "    if prediction == 1:\n",
    "        return \"Sarcastic\"\n",
    "    else:\n",
    "        return \"Not Sarcastic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8298af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for comment: 'Oh great, another Monday! I just love waking up early after the weekend.' -> \n",
      " Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "# Example usage of detection system\n",
    "test_headline = \"Oh great, another Monday! I just love waking up early after the weekend.\"\n",
    "\n",
    "print(f\"Prediction for comment: '{test_headline}' -> \\n {detect_sarcasm(test_headline)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34106275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for comment: 'Oh, how thoughtful! I really needed someone to explain the obvious to me.' -> \n",
      " Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "# Example usage of detection system\n",
    "test_headline = \"Oh, how thoughtful! I really needed someone to explain the obvious to me.\"\n",
    "print(f\"Prediction for comment: '{test_headline}' -> \\n {detect_sarcasm(test_headline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a43835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open(\"model.pkl\",'wb'))\n",
    "pickle.dump(tfidf,open(\"tfidf.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de98283f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
